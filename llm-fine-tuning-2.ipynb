{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":799923,"sourceType":"datasetVersion","datasetId":374}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport pandas as pd\n\n# Load JSON file\nfile_path = \"/kaggle/input/stanford-question-answering-dataset/train-v1.1.json\"\nwith open(file_path, \"r\", encoding=\"utf-8\") as file:\n    data = json.load(file)\n\n# Extract relevant information\nrecords = []\nfor topic in data[\"data\"]:\n    title = topic[\"title\"]\n    for paragraph in topic[\"paragraphs\"]:\n        context = paragraph[\"context\"]\n        for qas in paragraph[\"qas\"]:\n            question = qas[\"question\"]\n            question_id = qas[\"id\"]\n            answers = [ans[\"text\"] for ans in qas[\"answers\"]]  # Collect all possible answers\n            records.append([title, context, question, question_id, answers])\n\n# Convert to Pandas DataFrame\ndf = pd.DataFrame(records, columns=[\"Title\", \"Context\", \"Question\", \"Question_ID\", \"Answers\"])\n\n# Display DataFrame\nprint(df.head())\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-15T00:24:53.640248Z","iopub.execute_input":"2025-02-15T00:24:53.640558Z","iopub.status.idle":"2025-02-15T00:24:54.802553Z","shell.execute_reply.started":"2025-02-15T00:24:53.640526Z","shell.execute_reply":"2025-02-15T00:24:54.801578Z"}},"outputs":[{"name":"stdout","text":"                      Title  \\\n0  University_of_Notre_Dame   \n1  University_of_Notre_Dame   \n2  University_of_Notre_Dame   \n3  University_of_Notre_Dame   \n4  University_of_Notre_Dame   \n\n                                             Context  \\\n0  Architecturally, the school has a Catholic cha...   \n1  Architecturally, the school has a Catholic cha...   \n2  Architecturally, the school has a Catholic cha...   \n3  Architecturally, the school has a Catholic cha...   \n4  Architecturally, the school has a Catholic cha...   \n\n                                            Question  \\\n0  To whom did the Virgin Mary allegedly appear i...   \n1  What is in front of the Notre Dame Main Building?   \n2  The Basilica of the Sacred heart at Notre Dame...   \n3                  What is the Grotto at Notre Dame?   \n4  What sits on top of the Main Building at Notre...   \n\n                Question_ID                                    Answers  \n0  5733be284776f41900661182               [Saint Bernadette Soubirous]  \n1  5733be284776f4190066117f                [a copper statue of Christ]  \n2  5733be284776f41900661180                        [the Main Building]  \n3  5733be284776f41900661181  [a Marian place of prayer and reflection]  \n4  5733be284776f4190066117e       [a golden statue of the Virgin Mary]  \n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhuggingface_value = user_secrets.get_secret(\"huggingface\")\nwandb_value = user_secrets.get_secret(\"wandb\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T00:24:54.804699Z","iopub.execute_input":"2025-02-15T00:24:54.805038Z","iopub.status.idle":"2025-02-15T00:24:55.074437Z","shell.execute_reply.started":"2025-02-15T00:24:54.805016Z","shell.execute_reply":"2025-02-15T00:24:55.073459Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=huggingface_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T00:24:55.075780Z","iopub.execute_input":"2025-02-15T00:24:55.076064Z","iopub.status.idle":"2025-02-15T00:24:55.662122Z","shell.execute_reply.started":"2025-02-15T00:24:55.076032Z","shell.execute_reply":"2025-02-15T00:24:55.661433Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\nimport torch\n#TinyLlama/TinyLlama_v1.1\n#meta-llama/Llama-3.2-3B\n# Load the model and tokenizer\nmodel_name = \"meta-llama/Llama-3.2-3B\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name,device_map=\"auto\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T00:24:55.662889Z","iopub.execute_input":"2025-02-15T00:24:55.663177Z","iopub.status.idle":"2025-02-15T00:25:14.044140Z","shell.execute_reply.started":"2025-02-15T00:24:55.663155Z","shell.execute_reply":"2025-02-15T00:25:14.043460Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ba887007e804f19859f3cd293d679a8"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from datasets import Dataset , DatasetDict\nmax_length = 256\ndef tokenize_function(examples):\n    text = [f\"Context: {inp} \\nQuestions:\" for inp in examples[\"Context\"]]\n    \n    examples[\"input_ids\"] = tokenizer(text, truncation=True, padding=\"max_length\", max_length=max_length, return_tensors = \"pt\").input_ids\n    examples[\"labels\"] = tokenizer(examples[\"Question\"], truncation=True, padding=\"max_length\", max_length=max_length, return_tensors = \"pt\").input_ids\n    \n    return examples\n    \ndata = Dataset.from_pandas(df)\n\ntokenizer.pad_token = tokenizer.eos_token\ntokenized_dataset = data.map(tokenize_function, batched=True)\ntokenized_dataset = tokenized_dataset.remove_columns(['Title', 'Context', 'Question', 'Question_ID', 'Answers'])\ntokenized_dataset = tokenized_dataset.filter(lambda example,index:index%20==0,with_indices=True)\nsplit_dataset = tokenized_dataset.train_test_split(test_size=0.2)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T00:25:14.044989Z","iopub.execute_input":"2025-02-15T00:25:14.045689Z","iopub.status.idle":"2025-02-15T00:26:11.516407Z","shell.execute_reply.started":"2025-02-15T00:25:14.045649Z","shell.execute_reply":"2025-02-15T00:26:11.515558Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/87599 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6ef99412afe4f20b81f6825743ccb3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/87599 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30658a631b3b44fca7ca99d1fea5b640"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, TaskType\n\nlora_config = LoraConfig(\n    r=32,\n    lora_alpha = 32,\n    lora_dropout=0.05,\n    bias='none',\n    task_type = TaskType.SEQ_2_SEQ_LM\n)\npeft_model = get_peft_model(model,peft_config=lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T00:26:11.517263Z","iopub.execute_input":"2025-02-15T00:26:11.517581Z","iopub.status.idle":"2025-02-15T00:26:11.695781Z","shell.execute_reply.started":"2025-02-15T00:26:11.517547Z","shell.execute_reply":"2025-02-15T00:26:11.694880Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# from datasets import Dataset , DatasetDict\n# split_dataset = DatasetDict({\n#     \"train\": split_dataset[\"train\"].with_format(\"torch\"),  \n#     \"test\": split_dataset[\"test\"].with_format(\"torch\")\n# })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T00:26:11.696744Z","iopub.execute_input":"2025-02-15T00:26:11.697085Z","iopub.status.idle":"2025-02-15T00:26:11.700397Z","shell.execute_reply.started":"2025-02-15T00:26:11.697054Z","shell.execute_reply":"2025-02-15T00:26:11.699691Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from transformers import TrainingArguments , Trainer\ntraining_args = TrainingArguments(\n                    output_dir=\" ./llama_3.2_3b_fine-tuned\",\n                    learning_rate = 1e-5,\n                    num_train_epochs = 5,\n                    weight_decay = 0.01,\n                    # per_device_train_batch_size=2,\n                    # per_device_eval_batch_size=2,\n                    # gradient_accumulation_steps=4,\n                    auto_find_batch_size = True,\n                    evaluation_strategy  = 'epoch',\n                    save_strategy=\"epoch\",  # Save checkpoints at each epoch\n                    save_total_limit=2,  # Keep only the last 2 checkpoints to save space\n                    load_best_model_at_end=True,  # Load best model after training\n                    fp16=True)\n\ntrainer = Trainer(\n    model = peft_model,\n    # tokenizer = tokenizer,\n    args = training_args,\n    train_dataset=split_dataset[\"train\"],\n    eval_dataset=split_dataset[\"test\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T00:26:11.702088Z","iopub.execute_input":"2025-02-15T00:26:11.702330Z","iopub.status.idle":"2025-02-15T00:26:12.198140Z","shell.execute_reply.started":"2025-02-15T00:26:11.702310Z","shell.execute_reply":"2025-02-15T00:26:12.197258Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import wandb\n\nwandb.login(key=wandb_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T00:26:12.199323Z","iopub.execute_input":"2025-02-15T00:26:12.199619Z","iopub.status.idle":"2025-02-15T00:26:18.193067Z","shell.execute_reply.started":"2025-02-15T00:26:12.199586Z","shell.execute_reply":"2025-02-15T00:26:18.192367Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbahaa_beshoy\u001b[0m (\u001b[33mbahaa_beshoy-helwan-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T00:26:18.193821Z","iopub.execute_input":"2025-02-15T00:26:18.194466Z","iopub.status.idle":"2025-02-15T01:43:58.288019Z","shell.execute_reply.started":"2025-02-15T00:26:18.194440Z","shell.execute_reply":"2025-02-15T01:43:58.287359Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250215_002619-nwtlrpzc</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/bahaa_beshoy-helwan-university/huggingface/runs/nwtlrpzc' target=\"_blank\"> ./llama_3.2_3b_fine-tuned</a></strong> to <a href='https://wandb.ai/bahaa_beshoy-helwan-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/bahaa_beshoy-helwan-university/huggingface' target=\"_blank\">https://wandb.ai/bahaa_beshoy-helwan-university/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/bahaa_beshoy-helwan-university/huggingface/runs/nwtlrpzc' target=\"_blank\">https://wandb.ai/bahaa_beshoy-helwan-university/huggingface/runs/nwtlrpzc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4380' max='4380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4380/4380 1:17:29, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.324900</td>\n      <td>0.390363</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.372800</td>\n      <td>0.360835</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.365300</td>\n      <td>0.355824</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.361700</td>\n      <td>0.353955</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.358600</td>\n      <td>0.353474</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4380, training_loss=0.5923195651677101, metrics={'train_runtime': 4650.5546, 'train_samples_per_second': 3.767, 'train_steps_per_second': 0.942, 'total_flos': 7.610142874927104e+16, 'train_loss': 0.5923195651677101, 'epoch': 5.0})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"#resume_from_checkpoint=True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T01:43:58.288889Z","iopub.execute_input":"2025-02-15T01:43:58.289220Z","iopub.status.idle":"2025-02-15T01:43:58.293234Z","shell.execute_reply.started":"2025-02-15T01:43:58.289170Z","shell.execute_reply":"2025-02-15T01:43:58.292330Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from peft import PeftModel\n\n# Assuming 'trainer' is your fine-tuning trainer and 'lora_model' is the PEFT model.\nlora_model = trainer.model  # The model you trained using LoRA (PEFT)\n\n# Save the model and LoRA adapter weights\nmodel_save_path = './Llama_3.2_3b_fine_tuned_lora_model'\nlora_model.save_pretrained(save_directory=model_save_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T01:45:12.535433Z","iopub.execute_input":"2025-02-15T01:45:12.535754Z","iopub.status.idle":"2025-02-15T01:45:12.815338Z","shell.execute_reply.started":"2025-02-15T01:45:12.535729Z","shell.execute_reply":"2025-02-15T01:45:12.814277Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-49ad1684c1ef>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Optionally, save the LoRA configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlora_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeft_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'save_pretrained'"],"ename":"AttributeError","evalue":"'dict' object has no attribute 'save_pretrained'","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"from kaggle.api.kaggle_api_extended import KaggleApi\n\napi = KaggleApi()\napi.authenticate()\n\napi.dataset_create_new(folder_path='/kaggle/working/Llama_3.2_3b_fine_tuned_lora_model', dataset_name='adapter_model.safetensors')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T01:51:31.388378Z","iopub.execute_input":"2025-02-15T01:51:31.388725Z","iopub.status.idle":"2025-02-15T01:51:31.776875Z","shell.execute_reply.started":"2025-02-15T01:51:31.388698Z","shell.execute_reply":"2025-02-15T01:51:31.775772Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-d7a6929c3c81>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkaggle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaggle_api_extended\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKaggleApi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKaggleApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKaggleApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mApiClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\u001b[0m in \u001b[0;36mauthenticate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 raise IOError('Could not find {}. Make sure it\\'s located in'\n\u001b[0m\u001b[1;32m    408\u001b[0m                               \u001b[0;34m' {}. Or use the environment method. See setup'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                               \u001b[0;34m' instructions at'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Could not find kaggle.json. Make sure it's located in /root/.config/kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/"],"ename":"OSError","evalue":"Could not find kaggle.json. Make sure it's located in /root/.config/kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/","output_type":"error"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}